{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('StackOverflow_cleaned.csv',sep=\";\", index_col=0,converters={\"Title\": literal_eval,\n",
    "                                                                                 \"Body\": literal_eval,\n",
    "                                                                                  \"Tags\": literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24044 entries, 0 to 27048\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Title   24044 non-null  object\n",
      " 1   Body    24044 non-null  object\n",
      " 2   Score   24044 non-null  int64 \n",
      " 3   Tags    24044 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 939.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Score</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[core, dump, linux, segmentation, fault]</td>\n",
       "      <td>[process, linux, segmentation, fault, core, dump]</td>\n",
       "      <td>237</td>\n",
       "      <td>[linux, bash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[php, server, mysql, server, time, zone]</td>\n",
       "      <td>[hosting, package, godaddy, network, solution,...</td>\n",
       "      <td>12</td>\n",
       "      <td>[php, mysql]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[constraint, landscape, orientation]</td>\n",
       "      <td>[constraint, device, example, image, portrait,...</td>\n",
       "      <td>48</td>\n",
       "      <td>[ios, cocoa-touch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[loading, system, servicemodel, configuration,...</td>\n",
       "      <td>[net, wcf, wcf, configuration, client, applica...</td>\n",
       "      <td>64</td>\n",
       "      <td>[c#, .net]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[xml, serialization, inherited, type]</td>\n",
       "      <td>[question, object, model, xml, problem, quelle...</td>\n",
       "      <td>86</td>\n",
       "      <td>[c#]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>[xpath, query, html, table, work, firebug, app...</td>\n",
       "      <td>[question, target, candidate, week, applicatio...</td>\n",
       "      <td>21</td>\n",
       "      <td>[html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>[convert, generic, collection, datatable]</td>\n",
       "      <td>[collection, list, datatable, code, problem, p...</td>\n",
       "      <td>80</td>\n",
       "      <td>[c#]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>[aspnet, custom, validator, client, side, serv...</td>\n",
       "      <td>[reason, client, side, validation, event, side...</td>\n",
       "      <td>74</td>\n",
       "      <td>[c#, .net, asp.net]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>[django, python, web, framework]</td>\n",
       "      <td>[python, web, framework, time, bullet, framewo...</td>\n",
       "      <td>61</td>\n",
       "      <td>[python, django]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>[django, work, unicode, string]</td>\n",
       "      <td>[filter, character, django, cnprogcom, charact...</td>\n",
       "      <td>45</td>\n",
       "      <td>[python, django]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0             [core, dump, linux, segmentation, fault]   \n",
       "1             [php, server, mysql, server, time, zone]   \n",
       "2                 [constraint, landscape, orientation]   \n",
       "3    [loading, system, servicemodel, configuration,...   \n",
       "4                [xml, serialization, inherited, type]   \n",
       "..                                                 ...   \n",
       "550  [xpath, query, html, table, work, firebug, app...   \n",
       "551          [convert, generic, collection, datatable]   \n",
       "552  [aspnet, custom, validator, client, side, serv...   \n",
       "553                   [django, python, web, framework]   \n",
       "554                    [django, work, unicode, string]   \n",
       "\n",
       "                                                  Body  Score  \\\n",
       "0    [process, linux, segmentation, fault, core, dump]    237   \n",
       "1    [hosting, package, godaddy, network, solution,...     12   \n",
       "2    [constraint, device, example, image, portrait,...     48   \n",
       "3    [net, wcf, wcf, configuration, client, applica...     64   \n",
       "4    [question, object, model, xml, problem, quelle...     86   \n",
       "..                                                 ...    ...   \n",
       "550  [question, target, candidate, week, applicatio...     21   \n",
       "551  [collection, list, datatable, code, problem, p...     80   \n",
       "552  [reason, client, side, validation, event, side...     74   \n",
       "553  [python, web, framework, time, bullet, framewo...     61   \n",
       "554  [filter, character, django, cnprogcom, charact...     45   \n",
       "\n",
       "                    Tags  \n",
       "0          [linux, bash]  \n",
       "1           [php, mysql]  \n",
       "2     [ios, cocoa-touch]  \n",
       "3             [c#, .net]  \n",
       "4                   [c#]  \n",
       "..                   ...  \n",
       "550               [html]  \n",
       "551                 [c#]  \n",
       "552  [c#, .net, asp.net]  \n",
       "553     [python, django]  \n",
       "554     [python, django]  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import metrics as kmetrics\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "import gensim\n",
    "\n",
    "#X = data[\"Body\"]\n",
    "y = data[\"Tags\"]\n",
    "\n",
    "def transform_stc(my_text) :\n",
    "    \n",
    "    transf_desc_text = ' '.join(my_text)\n",
    "    return transf_desc_text\n",
    "\n",
    "X =  data['Body'].apply(lambda x : transform_stc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             process linux segmentation fault core dump\n",
       "1      hosting package godaddy network solution conve...\n",
       "2      constraint device example image portrait lands...\n",
       "3      net wcf wcf configuration client application n...\n",
       "4      question object model xml problem quelle surpr...\n",
       "                             ...                        \n",
       "550    question target candidate week application web...\n",
       "551    collection list datatable code problem propert...\n",
       "552    reason client side validation event side valid...\n",
       "553    python web framework time bullet framework adv...\n",
       "554    filter character django cnprogcom character qu...\n",
       "Name: Body, Length: 500, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_size=300\n",
    "w2v_window=5\n",
    "w2v_min_count=1\n",
    "w2v_epochs=100\n",
    "maxlen = 24 # adapt to length of sentences\n",
    "sentences = X.to_list()\n",
    "sentences = [gensim.utils.simple_preprocess(text) for text in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build & train Word2Vec model ...\n",
      "Vocabulary size: 2250\n",
      "Word2Vec trained\n"
     ]
    }
   ],
   "source": [
    "# Création et entraînement du modèle Word2Vec\n",
    "\n",
    "print(\"Build & train Word2Vec model ...\")\n",
    "w2v_model = gensim.models.Word2Vec(min_count=w2v_min_count, window=w2v_window,\n",
    "                                                vector_size=w2v_size,\n",
    "                                                seed=42,\n",
    "                                                workers=1)\n",
    "\n",
    "w2v_model.build_vocab(sentences)\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=w2v_epochs)\n",
    "model_vectors = w2v_model.wv\n",
    "w2v_words = model_vectors.index_to_key\n",
    "print(\"Vocabulary size: %i\" % len(w2v_words))\n",
    "print(\"Word2Vec trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Tokenizer ...\n",
      "Number of unique words: 2251\n"
     ]
    }
   ],
   "source": [
    "# Préparation des sentences (tokenization)\n",
    "\n",
    "print(\"Fit Tokenizer ...\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "x_sentences = pad_sequences(tokenizer.texts_to_sequences(sentences),\n",
    "                                                     maxlen=maxlen,\n",
    "                                                     padding='post') \n",
    "                                                   \n",
    "num_words = len(tokenizer.word_index) + 1\n",
    "print(\"Number of unique words: %i\" % num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de la matrice d'embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Embedding matrix ...\n",
      "Word embedding rate :  1.0\n",
      "Embedding matrix: (2251, 300)\n"
     ]
    }
   ],
   "source": [
    "# Création de la matrice d'embedding\n",
    "\n",
    "print(\"Create Embedding matrix ...\")\n",
    "w2v_size = 300\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, w2v_size))\n",
    "i=0\n",
    "j=0\n",
    "    \n",
    "for word, idx in word_index.items():\n",
    "    i +=1\n",
    "    if word in w2v_words:\n",
    "        j +=1\n",
    "        embedding_vector = model_vectors[word]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[idx] = model_vectors[word]\n",
    "            \n",
    "word_rate = np.round(j/i,4)\n",
    "print(\"Word embedding rate : \", word_rate)\n",
    "print(\"Embedding matrix: %s\" % str(embedding_matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle d'embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 24)]              0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 24, 300)           675300    \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 300)              0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 675,300\n",
      "Trainable params: 675,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Création du modèle\n",
    "\n",
    "input=Input(shape=(len(x_sentences),maxlen),dtype='float64')\n",
    "word_input=Input(shape=(maxlen,),dtype='float64')  \n",
    "word_embedding=Embedding(input_dim=vocab_size,\n",
    "                         output_dim=w2v_size,\n",
    "                         weights = [embedding_matrix],\n",
    "                         input_length=maxlen)(word_input)\n",
    "word_vec=GlobalAveragePooling1D()(word_embedding)  \n",
    "embed_model = Model([word_input],word_vec)\n",
    "\n",
    "embed_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exécution du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w2v= embed_model.predict(x_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 300)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_w2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest ONeVsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# transform output : \n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(y)\n",
    "y_bin = multilabel_binarizer.transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_w2v, y_bin, test_size=0.3, random_state=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "domestic-check",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T05:53:29.410116Z",
     "iopub.status.busy": "2021-07-13T05:53:29.409435Z",
     "iopub.status.idle": "2021-07-13T05:57:39.420988Z",
     "shell.execute_reply": "2021-07-13T05:57:39.421525Z",
     "shell.execute_reply.started": "2021-07-12T13:10:56.3161Z"
    },
    "papermill": {
     "duration": 250.136813,
     "end_time": "2021-07-13T05:57:39.421711",
     "exception": false,
     "start_time": "2021-07-13T05:53:29.284898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=OneVsRestClassifier(estimator=RandomForestClassifier()),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'estimator__class_weight': ['balanced'],\n",
       "                         'estimator__max_depth': [5, 25, 50],\n",
       "                         'estimator__min_samples_leaf': [1, 5, 10]},\n",
       "             return_train_score=True, scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize RandomForest with OneVsRest\n",
    "param_rfc = {\"estimator__max_depth\": [5, 25, 50],\n",
    "             \"estimator__min_samples_leaf\": [1, 5, 10],\n",
    "             \"estimator__class_weight\": [\"balanced\"]}\n",
    "\n",
    "multi_rfc_cv = GridSearchCV(OneVsRestClassifier(RandomForestClassifier()),\n",
    "                            param_grid=param_rfc,\n",
    "                            n_jobs=-1,\n",
    "                            cv=2,\n",
    "                            scoring=\"f1_weighted\",\n",
    "                            return_train_score = True,\n",
    "                            refit=True,\n",
    "                            verbose=3)\n",
    "# Fit on Sample data\n",
    "multi_rfc_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "objective-pharmacy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T05:57:39.664274Z",
     "iopub.status.busy": "2021-07-13T05:57:39.663526Z",
     "iopub.status.idle": "2021-07-13T05:57:39.667674Z",
     "shell.execute_reply": "2021-07-13T05:57:39.666987Z",
     "shell.execute_reply.started": "2021-07-12T13:14:16.860557Z"
    },
    "papermill": {
     "duration": 0.130171,
     "end_time": "2021-07-13T05:57:39.667822",
     "exception": false,
     "start_time": "2021-07-13T05:57:39.537651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator__class_weight': 'balanced', 'estimator__max_depth': 25, 'estimator__min_samples_leaf': 10}\n"
     ]
    }
   ],
   "source": [
    "rfc_cv_results = pd.DataFrame.from_dict(multi_rfc_cv.cv_results_)\n",
    "rfc_best_params = multi_rfc_cv.best_params_\n",
    "print(rfc_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "greatest-conducting",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T05:57:39.911785Z",
     "iopub.status.busy": "2021-07-13T05:57:39.910860Z",
     "iopub.status.idle": "2021-07-13T05:57:39.914003Z",
     "shell.execute_reply": "2021-07-13T05:57:39.914475Z",
     "shell.execute_reply.started": "2021-07-12T13:14:16.869174Z"
    },
    "papermill": {
     "duration": 0.127371,
     "end_time": "2021-07-13T05:57:39.914718",
     "exception": false,
     "start_time": "2021-07-13T05:57:39.787347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rfc_best_params_ok = {}\n",
    "for k, v in rfc_best_params.items():\n",
    "    rfc_best_params_ok[k.replace(\"estimator__\",\"\")] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "concerned-earth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T05:57:40.157477Z",
     "iopub.status.busy": "2021-07-13T05:57:40.156769Z",
     "iopub.status.idle": "2021-07-13T06:13:38.711950Z",
     "shell.execute_reply": "2021-07-13T06:13:38.712485Z",
     "shell.execute_reply.started": "2021-07-12T13:14:16.880333Z"
    },
    "papermill": {
     "duration": 958.681265,
     "end_time": "2021-07-13T06:13:38.712672",
     "exception": false,
     "start_time": "2021-07-13T05:57:40.031407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [(), (), (), (), ()]\n",
      "True: [('performance',), ('.net', 'c#'), ('bash',), ('node.js',), ('python',)]\n"
     ]
    }
   ],
   "source": [
    "# Refit RandomForestClassifier best_params with full dataset\n",
    "rfc_final_model = OneVsRestClassifier(RandomForestClassifier(**rfc_best_params_ok))\n",
    "rfc_final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_test_predicted_labels_tfidf_rfc = rfc_final_model.predict(X_test)\n",
    "\n",
    "# Inverse transform\n",
    "y_test_pred_inversed_rfc = multilabel_binarizer.inverse_transform(y_test_predicted_labels_tfidf_rfc)\n",
    "y_test_inversed = multilabel_binarizer.inverse_transform(y_test)\n",
    "print(\"Predicted:\", y_test_pred_inversed_rfc[0:5])\n",
    "print(\"True:\", y_test_inversed[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeorn\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Aeorn\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in labels with no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aeorn\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aeorn\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.073333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.359578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard</th>\n",
       "      <td>0.135028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.167364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.408667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RandomForest\n",
       "Accuracy       0.073333\n",
       "F1             0.359578\n",
       "Jaccard        0.135028\n",
       "Recall         0.167364\n",
       "Precision      0.408667"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def metrics_score(model, df, y_true, y_pred):\n",
    " \n",
    "    if(df is not None):\n",
    "        temp_df = df\n",
    "    else:\n",
    "        temp_df = pd.DataFrame(index=[\"Accuracy\", \"F1\",\n",
    "                                      \"Jaccard\", \"Recall\",\n",
    "                                      \"Precision\"],\n",
    "                               columns=[model])\n",
    "        \n",
    "    scores = []\n",
    "    scores.append(metrics.accuracy_score(y_true, \n",
    "                                         y_pred))\n",
    "    scores.append(metrics.f1_score(y_pred, \n",
    "                                   y_true, \n",
    "                                   average='weighted'))\n",
    "    scores.append(metrics.jaccard_score(y_true, \n",
    "                                        y_pred, \n",
    "                                        average='weighted'))\n",
    "    scores.append(metrics.recall_score(y_true, \n",
    "                                       y_pred, \n",
    "                                       average='weighted'))\n",
    "    scores.append(metrics.precision_score(y_true, \n",
    "                                          y_pred, \n",
    "                                          average='weighted'))\n",
    "    temp_df[model] = scores\n",
    "    \n",
    "    return temp_df\n",
    "    \n",
    "df_metrics_compare = metrics_score(\"RandomForest\", \n",
    "                                   df=None,\n",
    "                                   y_true = y_test,\n",
    "                                   y_pred = y_test_predicted_labels_tfidf_rfc)\n",
    "df_metrics_compare\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f7e7a8048ab9569ccd7edaade9a9d1227dad3950a1e5a7122e71aad3389e168"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
